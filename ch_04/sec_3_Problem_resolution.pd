\section {Основные проблемы, их решение}

В данном разделе будут рассмотрены основные проблемы, с которыми мы столкнулись, применив описанную в предыдущем разделе метрику, решения (улучшения), применённые к метрике, позволившие уменьшить эффект, производимый некоторыми из этих проблем.

Будут рассмотрены некоторые проблемы, уже упомянутые в разделе \ref{ch01-yarn} и специфичные для YARN:
  
  * синсеты-дубликаты
  * многопонятийные/смешанные синсеты
  * неполнота YARN

Также и некоторые, характерные для задачи в целом:
  
  * длинные синсеты
  * полисемия

### Синсеты-дубликаты ###

Как было упомянуто в предыдущем разделе, после применения метрики на основе меры Жаккара, количество полученных связей оказалось непозволительно большим. Основным фактором, приведшим к такому результату, были именно синсеты-дубликаты. Напомним, дубликатами мы называем синсеты, описывающие одно и то же понятие естественного языка.

Чтобы продемонстрировать масштаб проблемы, рассмотрим множество синсетов, связанных с _SID-10204565-N [hope] (someone (or something) on which expectations are centered)_ с отсечением по весу $0.2$ (синсеты сгруппированы по понятиям):

* надежда как возможность в будущем
    + s1816 [возможность, допустимость, вероятность, случай, надежда]
    + s277 [перспектива, грядущее, будущее, будущность, надежда, шанс, ожидание]
    + s30159 [мечта, надежда, ожидание, чаяние]
    + s30630 [надежда, ожидание, упование]
    + s30631 [надежда, упование]
    + s30632 [надежда, упование, чаяние]
* ложная надежда, (само)обман
    + s22799 [воздушные замки, ложное представление, видимость, заблуждение, иллюзия, надежда, обман, химера]
* надежда как способ пережить проблему
    + s13028 [надежда, прибежище, утешение]
* надежда как опора
    + s30628 [надежда, надёжа, оплот]
    + s30629 [надежда, надёжа, опора]
    + s6550 [надежда, основание]

Всего 11 связей, что вообще приемлимо немного (10-15 синсетов можно просмотреть вручную). Но все-таки кажется разумным сперва "схлопнуть" синсеты, описывающие одно понятие в один синсет, а уже потом пытаться связать этот объединенный синсет с синсетом из PWN. Кроме того, для подавляющего числа других синсетов из BCs количество связей значительно превышает 11, и без отсечения дубликатов дальнейший процессинг попросту невозможен.

Заметим, что "схлапывание" синсетов --- вообще говоря отдельная задача, непосредственно не связанная с задачей выравнивания. Как уже было отмечено, YARN находится в стадии активной разработки, и исследование подходов решения проблемы дубликатов --- одно из основных направлений работы.

Поскольку редактирование существующих синсетов выходит за рамки решаемой задачи, было принято решение не объединять синсеты с одним смыслом, но группировать, воспользовавшись некоторой разумной эвристикой для классификации двух синсетов как описывающих одно понятие языка. В частности в работе [@yarn_add-remove-confirm] для нахождения потенциальных дубликатов предлагается рассмотреть все пары синсетов, пересекающиеся по двум и более словам.
Авторы, ссылаясь на работу [@yarn_tale-of-12], утверждают, что большинство таких пар являются парами из двух синсетов-дубликатов.

Именно идея объединения синсетов, пересекающихся хотя бы по двум словам, была взята нами за основу эвристики. После нахождения для данного синсета из PWN множества кандидатов из YARN, мы жадно объединяем кандидатов в смысловые группы --- кластеры. Кроме, собственно, эвристики пересечения по двум, будем использовать следующие дополнительные соображения:

* перед сравнением разумно пропустить синсеты через стеммер, т.к. в YARN встречаются синсеты, в которых слова даны, например, в форме множественного числа
* если два одноэлементных синсета полностью совпадают, их тоже будем считать дубликатами.

Сформулируем алгоритм формирования кластеров (повторяем шаги а)--в), пока множество нерасмотренных синсетов не станет пустым):

1. берем любой еще не рассмотренный нами синсет
2. создаём из него одноэлементный кластер
3. последовательно перебираем множество нерассмотренных синсетов
    + добавляем в кластер те, которые пересекаются по обозначенному выше критерию с хотя бы одним элементомa кластера (синсетом, добавленным на предыдущем шаге)
    + синсеты, добавляющиеся в кластер мы исключаем из дальнейшего рассмотрения

Для каждого класса мы определяем ровно один синсет-представитель, в дальнейшем будем рассматривать только связи между исходным синсетом из PWN и представителями кластеров. В качестве представителя выбирается синсет с наибольшим весом.

\image {hope_clustering_only} {Кластеризованный граф связей для SID-10204565-N (hope)}

На \inlref{рисунке}{img:hope_clustering_only} изображен подграф для _SID-10204565-N [hope]_, разбитый на кластеры. Синсеты были объединены в кластеры согласно разбиению по смыслам, использованном в списке выше за исключением синсета _s6550 [надежда, основание]_, который был выделен в отдельный одноэлементный кластер.

Разбиение на кластеры значительно улучшило свойства графа связей:

  * существенно уменьшилось число связей
  * для подавляющего числа синсетов из PWN наилучший кандидат на связывание стал находиться среди первых 15 синсетов

### Полисемия ###
\label {ch04-polysemy}

При переводе мы рассматриваем все слова исходного синсета, и если какое-нибудь из них полисемично, то в графе каждый смысл этого слова потенциально индуцирует по ребру (а вероятно и не по одному). Понятно, что среди полученных связей будет достаточно избытычных, с синсетами из YARN, не относящимися к исходному синсету. В идеале нам хотелось бы опеределить метрику таким образом, чтобы избыточные связи обладали меньшим весом, чем связи с синсетами YARN, близкими по смыслу к исходному.

В общем случае разрешить полисемию можно только посредством глубокого анализа определений синсетов, тезаурусных связей и т.д. Провести такой анализ автоматически представляются достаточно трудной задачей. В случае с YARN в силу отсутствия тезаурусных связей, определений (для большинства синсетов) такой анализ и вовсе невозможен, потому проблему полисемии мы будем решать посредством применения краудсорсинга (о чем будет рассказано в главе \ref{ch05}).

В следующих подразделах мы рассмотрим несколько частных случаев проявления полисемии, для которых посредством изменения метрики получилось существенно улучшить её релевантность.

### Длинные и смешанные синсеты ###

Длинным синсетом мы условно называем синсет, состоящий из более чем двух-трёх слов. Смешанным --- синсет, включающий в себя более одного понятия естественного языка. Понятно, что в тезаурусе в идеале не должно быть смешанных синсетов, и каждому синсету должно соответствовать ровно одно понятие естественного языка.

Однако в действительности некоторые синсеты могут быть настолько близки по смыслу друг к другу, что даже эксперту-лингвисту сложно будет однозначно определить, к одному они относятся понятию или к разным (и, соответственно, если объединить, сложно определить, является ли синсет смешанным (определяющим два близких понятия)).
Подробнее об этом и других затруднениях, возникающих при построении тезаурусов можно прочесть в [@bn-romanian].

Кроме того, YARN является ресурсом в стадии активной разработки, вследствие чего в нем значительно чаще встречаются синсеты, содержащие слова более одного понятия.

Смешанный синсет может и не являться длинным, однако для YARN это наблюдение зачастую выполняется. Мы рассмотрим случай, когда длинный синсет (тем более если он и смешанный) почти наверняка существенно ухудшит результат применения меры Жаккара, предложим способ нивелировать этот эффект.

При задании веса в формуле \ref{eq:w1} мы использовали максимум, причем максимум брался по всем переводным группам всех слов исходного синсета языка $A$.
Заметим, что если в синсете есть слово $\alpha$, относящееся к более, чем одному понятию, то в случае, когда его перевод близок по Жаккару к синсету $b \in B$ (т.е. значение $w=max \{ JC'(x, a) \; | \; x \in \tau(\{\alpha\}) \}$ достаточно высоко), между $a$ и $b$ будет ребро веса $\leqslant w$, даже в том случае, когда $\alpha$ --- единственное слово $a$, имеющее переводную связь с $b$. Для небольших синсетов это не представляет существенных затруднений, однако чем больше слов в синсете, тем вероятнее появление такого рода избыточных связей.

Из формулировки проблемы следует и идея её решения --- накладывать штраф на связь, если менее $\mu\%$ слов синсета участвуют в ней.
В качестве функции штрафа удобно выбрать такую, которая при небольших отклонениях $h < \mu$ не вносила бы существенного вклада в веса, однако чтобы с уменьшением $h$ множитель штрафа уменьшался сильнее, в пределе ($h \to 0$) к $0$. Из этих соображений функция штрафа была выбрана на основе функции нормального распределения:

\begin{equation*}
  m(h \; | \; \mu, \sigma) =
    \begin {cases}
      \frac{f(h)}{f(\mu)}, & h < \mu \\
      1, & \mathrm{ иначе }
    \end {cases}
\end{equation*}

\begin{equation*}
  f(x \; | \; \mu, \sigma) = \frac{1}{\sigma\sqrt{2\pi} } \; e^{ -\frac{(x-\mu)^2}{2\sigma^2} }
\end{equation*}

В качестве параметров распределения были взяты следующие значения:

* матожидание: $\mu = 0.5$, т.е. штраф накладывается только в том случае, когда менее половины слов синсета $a$ связаны с $b$
* стандартное отклонение: $\sigma = 0.2$

### Полисемия на уровне синонимических рядов ###

\label{ch04-syn-polysemy}

Применительно к задаче связывания полисемия на уровне рядов порождает ситуацию, когда нам не всегда достаточно анализа синсетов как множеств синонимов и их переводов, но желательно также учитывать определения, указанные в синсетах.

В разделе \ref{ch01-syn-polysemy} в качестве примера нами рассматривались синсеты PWN, состоящие из единственного слова _force_:
  
* SID-05201846-N [force] (a powerful effect or influence)
* SID-11479041-N [force] ((physics) the influence that produces a change in a physical quantity)
* SID-08224784-N [force] (a group of people having the power of effective action)

Аналогично, в YARN существует 7 синсетов с наборами слов _[сила]_, каждый из них оснащен своим определением. Строя подграф для, например, _SID-11479041-N_ мы получим кластер из 7 этих синсетов, связанный с _SID-11479041-N_ ребром веса $1$, причем представитель будет выбран произвольным образом (тогда как разумнее было бы выбрать именно тот, который обладает значением силы как термина из физики).

\label{ch04-wikt-glosses}

Однако учет определений имеет даже больший потенциал применений. Предположим, наборы синонимов в переводе у нас тоже будут оснащены краткими определениями, которые будут его отличать от других наборов в переводе данного слова. Например для переводов слова _force_ (данные из Wiktionary):

1. [сила] (physical quantity that denotes ability to accelerate a body)
1. [сила, мощь, дурь] (anything that is able to make a big change in person or thing)
1. [власть] (law: legal validity)
1. [сила, насилие] (law: unlawful violence or lawful compulsion)

Сравнив определение из первого перевода c определением синсета из PWN, мы поймем, что из четырёх предложенных переводов нам интересен именно первый.

Сравнивать определения синсетов двух связываемых тезаурусов можно было бы, например, применяя машинный перевод к одному из определений, сравнивая затем получившиеся предложения как последовательности слов. Однако мы посчитали, что реализовывать это нецелесообразно, т.к. на практике определениями снабжено менее $5 \%$ синсетов YARN.

Покрытие определениями переводов в используемом нами словаре Wiktionary значительно шире. Кроме того, определения даны на том же языке, что и определения исходного (переводимого) синсета, что позволяет сравнивать их как последовательности слов и без применения машинного перевода.

Сравнивать определения как последовательности слов можно различными способами. Однако заметим:

- перед нами не стоит задача точного сравнения определений, нам нужно только различать одни переводы от других
- определения в Wiktionary как правило короче определений из PWN, содержат несколько ключевых слов, которые как правило отсутствуют в определениях других переводов

В силу соображений, данных выше, мы нашли целесообразным использовать следующий простой подход:

* преобразуем определения перевода $t$, исходного синсета $a$ в множествa слов $ws(t)$, $ws(a)$
    * нормализуем формы слов с помощью стеммера
* за метрику похожести определений возьмём $s(t, a) = \frac { ws(t) \cap ws (a) } { ws(t) }$

Функция веса ребра между синсетами $a$, $b$ тогда примет следующий вид:

\begin{equation} \label{eq:w2}
  w (a \in A, b \in B) = max \{ p \cdot JC'(t, b) + (1 - p) \cdot s(t, b) \; | \; t \in \tau(a) \}
\end{equation}

Где $p$ - некий фиксированный коэфициент. Нами был использован $p = 0.7$.
